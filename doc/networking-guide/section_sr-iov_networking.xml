<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE section [
<!ENTITY % openstack SYSTEM "../common/entities/openstack.ent">
%openstack;
]>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
         xml:id="section_sr-iov_networking">
  <title>SR-IOV Networking</title>
  <para>The single root I/O virtualization (SR-IOV) interface is an extension
    to the PCI Express (PCIe) specification. SR-IOV allows a device, such
    as a network adapter, to separate access to its resources among various
    PCIe hardware functions. These functions consist of the following
    types:</para>
  <itemizedlist>
    <listitem><para>PCIe Physical Function (PF): This function is the
        primary function of the device and advertises the device's SR-IOV
        capabilities. The PF is associated with the Hyper-V parent partition
        in a virtualized environment.</para></listitem>
    <listitem><para>One or more PCIe Virtual Functions (VFs): Each VF is
        associated with the device's PF. A VF shares one or more physical
        resources of the device, such as a memory and a network port, with
        the PF and other VFs on the device. Each VF is associated with a
        Hyper-V child partition in a virtualized environment.</para></listitem>
  </itemizedlist>
  <para>There are two ways that a SR-IOV port can be connected:</para>
  <itemizedlist>
    <listitem><para>Directly connected to its VF.</para></listitem>
    <listitem><para>Connected with a <literal>macvtap</literal> device that
        resides on the host, which is then connected to the corresponding VF.</para></listitem>
  </itemizedlist>
  <para>Each PF and VF is assigned a unique PCI Express Requester ID (RID)
    that allows an I/O memory management unit (IOMMU) to differentiate
    between different traffic streams and apply memory and interrupt
    translations between the PF and VFs. This allows traffic streams to be
    delivered directly to the appropriate Hyper-V parent or child partition.
    As a result, nonprivileged data traffic flows from the PF to VF without
    affecting other VFs.</para>
  <para>SR-IOV enables network traffic to bypass the software switch layer
    of the Hyper-V virtualization stack. Because the VF is assigned to a
    child partition, the network traffic flows directly between the VF and
    child partition. As a result, the I/O overhead in the software emulation
    layer is diminished and achieves network performance that is nearly the
    same performance as in nonvirtualized environments.</para>
  <section xml:id="sect-support-for-nova">
    <title>Compute support for SR-IOV Networking</title>
    <para>Compute support for SR-IOV enables scheduling an instance with SR-IOV
      ports based on their network connectivity. The OpenStack Networking
      ports' associated physical networks have to be considered in making
      the scheduling decision. PCI Whitelist has been enchanced to allow
      tags to be associated with PCI devices. PCI devices available for SR-IOV
      networking should be tagged with <literal>physical_network label</literal>.</para>
    <para>For SR-IOV networking, a pre-defined tag <literal>physical_network</literal>
      is used to define the physical network to which the devices are attached.
      A whitelist entry is defined as:</para>
    <screen>["vendor_id": "<replaceable>id</replaceable>",] ["product_id": "<replaceable>id</replaceable>",]
["address": "[[[[<replaceable>domain</replaceable>]:]<replaceable>bus</replaceable>]:][<replaceable>slot</replaceable>][.[<replaceable>function</replaceable>]]" |
"devname": "<replaceable>Ethernet_Interface_Name</replaceable>",]
"physical_network":"<replaceable>Name_String_of_the_Physical_Network</replaceable>"</screen>
    <para>Here <replaceable>id</replaceable> can be an asterisk (*) or a valid
      vendor or product ID as displayed by the Linux utility <literal>lspci</literal>.
      The address uses the same syntax as in <literal>lspci</literal>. The
      <literal>devname</literal> can be a valid PCI device name. The only
      device names that are supported are those displayed by the Linux
      utility <command>ifconfig -a</command> and correspond to either
      a PF or a VF on a vNIC.</para>
    <para>If the device defined by the address or <literal>devname</literal>
      corresponds to a SR-IOV PF, all VFs under the PF will match the entry.</para>
    <para>Multiple whitelist entries per host are supported.</para>
  </section>
  <section xml:id="sect-support-for-neutron">
    <title>OpenStack Networking support for SR-IOV</title>
    <para>OpenStack Networking support for SR-IOV requires ML2 Plugin with
      SR-IOV supporting mechanism driver. Currently there is a ML2 Mechanism
      Driver for SR-IOV capable NIC based switching (HW VEB). There are
      network adapters from different vendors that vary by supporting various
      functionality. If VF link state update is supported by a vendor network
      adapter, the SR-IOV NIC L2 agent should be deployed to leverage this
      functionality.</para>
  </section>
  <section xml:id="sect-VM-creation-vNIC">
    <title>Virtual Machine creation flow with SR-IOV vNIC</title>
    <procedure>
    <!--    <title>Virtual Machine creation flow with SR-IOV vNIC</title>-->
      <step><para>Create one or more OpenStack Networking ports:</para>
        <screen><prompt>#</prompt> <userinput>neutron port-create <replaceable>net-id</replaceable> \
--binding:vnic-type <replaceable>direct | macvtap | normal</replaceable></userinput></screen></step>
<step><para>Boot the VM with one or more OpenStack Networking ports:</para>
        <screen><prompt>#</prompt> <userinput>nova boot --flavor m1.large --image <replaceable>image</replaceable>
--nic port-id=<replaceable>port1</replaceable> --nic port-id=<replaceable>port2</replaceable> <replaceable>vm_name</replaceable></userinput></screen></step>
    </procedure>
    <note><para>In the Compute boot API, users can specify either a
        <literal>port-ID</literal> or a <literal>net-ID</literal>. If a
        <literal>net-ID</literal> is specified, it is assumed that the user is
        requesting a normal virtual port (which is not an SR-IOV port).</para></note>
  </section>
  <section xml:id="sect-SR-IOV_configuration">
    <title>SR-IOV Configuration</title>
    <para>Configuring SR-IOV networking involves configuring the OpenStack
      Networking server, the Compute nodes and SR-IOV network agent.</para>
    <section xml:id="sect-SR-IOV_configuration-neutron">
      <title>OpenStack Networking Server</title>
      <para>Using ML2 Neutron plugin modify <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename>:</para>
      <programlisting language="ini">[ml2]
tenant_network_types = vlan
type_drivers = vlan
mechanism_drivers = openvswitch,sriovnicswitch

[ml2_type_vlan]
network_vlan_ranges = physnet1:2:100</programlisting>
<para>Add supported PCI vendor VF devices, defined by <literal>vendor_id:product_id</literal>
        according to the PCI ID Repository in the
        <filename>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</filename>:</para>
      <programlisting language="ini">[ml2_sriov]
supported_pci_vendor_devs = vendor_id:product_id</programlisting>
      <para>Example for Intel NIC that supports SR-IOV:</para>
      <screen>supported_pci_vendor_devs = 8086:10ca</screen>
      <para>If SR-IOV network adapters support VF link state setting and
        <literal>admin</literal> state management is desired, make sure to
        add the following setting in the
        <filename>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</filename>:</para>
      <programlisting language="ini">[ml2_sriov]
agent_required = True</programlisting>
      <para>Neutron server should be run with the two configuration files
        <filename>/etc/neutron/plugins/ml2/ml2_conf.in</filename> and
        <filename>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</filename></para>
      <screen>neutron-server --config-file <replaceable>/etc/neutron/neutron.conf</replaceable>
--config-file <replaceable>/etc/neutron/plugins/ml2/ml2_conf.ini</replaceable>
--config-file <replaceable>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</replaceable></screen>
    </section>
    <section xml:id="sect-SR-IOV_configuration-nova-compute">
      <title>Compute</title>
      <para>On each compute node, associate the VFs available to
        each physical network. This is performed by configuring
        <literal>pci_passthrough_whitelist</literal> in <filename>/etc/nova/nova.conf</filename>.
        For example:</para>
      <screen>pci_passthrough_whitelist = {"address":"*:0a:00.*","physical_network":"physnet1"}</screen>
      <para>This associates any VF with address that includes '<literal>:0a:00.</literal>'
        in its address to the physical network <literal>physnet1</literal>.
        After configuring the whitelist you have to restart <literal>nova-compute</literal>
        service.</para>
      <para>When using <literal>devstack pci_passthrough_whitelist</literal>
        can be configured in <filename>local.conf</filename> file. For example:</para>
      <programlisting language="ini">[[post-config|$NOVA_CONF]]
[DEFAULT]
pci_passthrough_whitelist = {"'"address"'":"'"*:02:00.*"'","'"physical_network"'":"'"default"'"}</programlisting>
    </section>
    <section xml:id="sect-SR-IOV_configuration-neutron-agent">
      <title>SR-IOV neutron agent</title>
      <para>If the hardware supports it and you want to enable changing the
        port <literal>admin_state</literal>, you have to run the OpenStack Networking
        SR-IOV agent.</para>
      <note><para>If you configured <literal>agent_required</literal>=<replaceable>True</replaceable>
          on the OpenStack Networking server, you must run the Agent on each
          compute node.</para></note>
      <para>In <filename>/etc/neutron/plugins/ml2/ml2_conf.ini</filename>
        ensure you have the following:</para>
      <programlisting language="ini">[securitygroup]
firewall_driver = neutron.agent.firewall.NoopFirewallDriver</programlisting>
      <para>Modify <filename>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</filename>
        as follows:</para>
      <programlisting language="ini">[sriov_nic]
physical_device_mappings = physnet1:eth1
exclude_devices =</programlisting>
      <para>where:</para>
      <itemizedlist>
        <listitem><para><literal>physnet1</literal> is the physical network</para></listitem>
        <listitem><para><literal>eth1</literal> is the physical function (PF)</para></listitem>
        <listitem><para><literal>exclude_devices</literal> is empty so all
          the VFs associated with <literal>eth1</literal> may be configured
          by the agent</para></listitem>
      </itemizedlist>
      <para>After modifying the configuration file, start the OpenStack
        Networking SR-IOV agent:</para>
      <screen><prompt>#</prompt> <userinput>neutron-sriov-nic-agent \
--config-file <replaceable>/etc/neutron/neutron.conf</replaceable> \
--config-file <replaceable>/etc/neutron/plugins/ml2/ml2_conf.ini</replaceable> \
--config-file <replaceable>/etc/neutron/plugins/ml2/ml2_conf_sriov.ini</replaceable></userinput></screen>
      <note><para>If you want to exclude some of the VFs so the agent does
          not configure them, you need to list them in the <literal>sriov_nic</literal>
          section. For example:</para></note>
      <screen>exclude_devices = eth1:0000:07:00.2; 0000:07:00.3, eth2:0000:05:00.1; 0000:05:00.2</screen>
      <para>For more information, refer
        <link xlink:href="http://community.mellanox.com/docs/DOC-1484">
        Openstack ML2 SR-IOV driver support
          </link></para>
    </section>
  </section>
</section>
