<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook"
    xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="troubleshooting-openstack-object-storage">
<title>Troubleshooting OpenStack Object Storage</title>
        <para>For OpenStack Object Storage, everything is logged in /var/log/syslog (or messages on some distros). Several settings enable further customization of logging, such as log_name, log_facility, and log_level, within the object server configuration files.</para> 
        <section xml:id="handling-drive-failure">
            <title>Handling Drive Failure</title>
       <para> In the event that a drive has failed, the first step is to make sure the drive is unmounted. This will make it easier for OpenStack Object Storage to work around the failure until it has been resolved. If the drive is going to be replaced immediately, then it is just best to replace the drive, format it, remount it, and let replication fill it up.</para>
       <para>If the drive can’t be replaced immediately, then it is best to leave it unmounted, and remove the drive from the ring. This will allow all the replicas that were on that drive to be replicated elsewhere until the drive is replaced. Once the drive is replaced, it can be re-added to the ring.</para>
       <para>Rackspace has seen hints at drive failures by looking at error messages in /var/log/kern.log -
        do consider checking this in your monitoring</para>
        </section>

        <section xml:id="handling-server-failure">
    
    <title>Handling Server Failure</title>

            <para>If a server is having hardware issues, it is a good idea to make sure the OpenStack Object Storage services are not running. This will allow OpenStack Object Storage to work around the failure while you troubleshoot.</para>
            
            <para>If the server just needs a reboot, or a small amount of work that should only last a couple of hours, then it is probably best to let OpenStack Object Storage work around the failure and get the machine fixed and back online. When the machine comes back online, replication will make sure that anything that is missing during the downtime will get updated.</para>
            
            <para>If the server has more serious issues, then it is probably best to remove all of the server’s devices from the ring. Once the server has been repaired and is back online, the server’s devices can be added back into the ring. It is important that the devices are reformatted before putting them back into the ring as it is likely to be responsible for a different set of partitions than before.</para>
</section>   
        <section xml:id="detecting-failed-drives">      
<title>Detecting Failed Drives</title>
            
            <para>It has been our experience that when a drive is about to fail, error messages will spew into /var/log/kern.log. There is a script called swift-drive-audit that can be run via cron to watch for bad drives. If errors are detected, it will unmount the bad drive, so that OpenStack Object Storage can work around it. The script takes a configuration file with the following settings:
           </para> 
            <programlisting>
            [drive-audit]
            Option 	Default 	Description
            log_facility 	LOG_LOCAL0 	Syslog log facility
            log_level 	INFO 	Log level
            device_dir 	/srv/node 	Directory devices are mounted under
            minutes 	60 	Number of minutes to look back in /var/log/kern.log
            error_limit 	1 	Number of errors to find before a device is unmounted
            </programlisting>
            <para>This script has only been tested on Ubuntu 10.04, so if you are using a different distro or OS, some care should be taken before using in production.
        </para></section>
</chapter>
