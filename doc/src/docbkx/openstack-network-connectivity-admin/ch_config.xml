<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="ch_config">
    <title>Required Configuration for OpenStack Identity &amp; Compute</title>

    <para>Using OpenStack Networking requires particular configuration and
    setup steps for both the OpenStack Identity Service and the OpenStack
    Compute Service.  This chapter describes these steps.</para>
    <section xml:id="keystone">
        <title>OpenStack Identity</title>
        <procedure>
            <title>To configure OpenStack Identity for use with OpenStack
                Networking</title>
            <step>
                <title>To Create an OpenStack Networking Service
                    Entry</title>
                <para>OpenStack Networking needs to be available in
                    the  OpenStack Compute service catalog.  The steps
                    for this depend on whether you are using the SQL
                    catalog driver or the template catalog
                    driver.</para>
                <para>With the <emphasis>SQL driver</emphasis>, for a
                    given region ($REGION), IP address of the
                    OpenStack Networking server ($IP), and service ID
                    ($ID) returned by the OpenStack Compute service
                    catalog, run: </para>
                <screen><userinput><?db-font-size 75%?>keystone service-create --name neutron --type network --description 'OpenStack Networking Service'</userinput></screen>
                <para>Make a note of the ID returned by the command
                    and put it in the $ID location.</para>
<screen><userinput>keystone endpoint-create --region $REGION --service-id $ID --publicurl 'http://$IP:9696/' --adminurl 'http://$IP:9696/' --internalurl 'http://$IP:9696/'</userinput></screen>
                <para>Here's an example with real values:</para>
                <screen><userinput><?db-font-size 75%?><prompt>$</prompt> <userinput>keystone service-create --name neutron --type network --description 'OpenStack Networking Service'</userinput></userinput></screen>
                <screen>+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description | OpenStack Networking Service     |
| id          | 26a55b340e254ad5bb78c0b14391e153 |
| name        | neutron                          |
| type        | network                          |
+-------------+----------------------------------+</screen>
                <screen><prompt>$</prompt> <userinput>keystone endpoint-create --region myregion --service-id 26a55b340e254ad5bb78c0b14391e153 \
--publicurl "http://10.211.55.17:9696/" --adminurl "http://10.211.55.17:9696/" --internalurl "http://10.211.55.17:9696/" </userinput></screen>
                <para>With the <emphasis>template driver</emphasis>,
                    for a given region ($REGION) and IP address of the
                    OpenStack Networking server ($IP), add the
                    following content to your OpenStack Compute
                    catalog template file (default_catalog.templates). </para>
                <screen><computeroutput>catalog.$REGION.network.publicURL = http://$IP:9696
catalog.$REGION.network.adminURL = http://$IP:9696
catalog.$REGION.network.internalURL = http://$IP:9696
catalog.$REGION.network.name = Network Service </computeroutput></screen>
                <para>Here is an example with real values:</para>
                <programlisting>catalog.$Region.network.publicURL = http://10.211.55.17:9696
catalog.$Region.network.adminURL = http://10.211.55.17:9696
catalog.$Region.network.internalURL = http://10.211.55.17:9696
catalog.$Region.network.name = Network Service</programlisting>

            </step>
            <step>
                <title>Create OpenStack Networking Service
                    User</title>
                <para>For OpenStack Compute to speak to the OpenStack Networking API, and for some
                    internal components of OpenStack Networking to communicate with the OpenStack
                    Networking API, you need to provide them with admin user credentials that they
                    can use when accessing the OpenStack Networking API.  The suggested approach is
                    to create a special 'service' tenant, create a ‘neutron’ user within this
                    tenant, and to assign this user an 'admin' role. Kindly check the ID for user,
                    role and tenant.</para>
                <para>For example: </para>
                <note><para>A <literal>get_id</literal> shell function is used
                to store the id of newly created objects. This function needs
                to be defined:
                <screen><prompt>$</prompt> <userinput>function get_id () {
     echo `"$@" | awk '/ id / { print $4 }'`
}</userinput></screen>
                It can be stored in your shell configuration file
                (usually <filename>~/.bashrc</filename>) to make it permanently
                available.
                </para></note>
                <screen><prompt>$</prompt> <userinput>ADMIN_ROLE=$(get_id keystone role-create --name=admin)
</userinput></screen>
                <screen><prompt>$</prompt> <userinput>NEUTRON_USER=$(get_id keystone user-create --name=neutron --pass="$NEUTRON_PASSWORD" --email=demo@example.com --tenant-id service)
</userinput></screen>
                <screen><prompt>$</prompt> <userinput>keystone user-role-add --user_id $NEUTRON_USER --role_id $ADMIN_ROLE --tenant_id service</userinput></screen>
            </step>
        </procedure>
        <para> See the OpenStack Installation Guides for more details
            about creating service entries and service users.</para>
    </section>
    <section xml:id="nova_with_neutron">
        <title>OpenStack Compute</title>
        <para>Unlike traditional OpenStack Compute deployments, when
            OpenStack Networking is in use, OpenStack Compute should
            not run a nova-network. Instead, OpenStack Compute
            delegates almost all of the network-related decisions to
            OpenStack Networking. Tenant-facing API calls to manage
            objects like security groups + floating IPs are proxied
            by OpenStack Compute to OpenStack Network APIs.  However,
            operator-facing tools (e.g., nova-manage) are not proxied
            and therefore should NOT be used as these calls are not
            proxied.</para>
        <warning>
        <para>Therefore, it is very important that you refer to this
            guide when configuring networking, rather than relying on
            OpenStack Compute networking documentation or past
            experience with OpenStack Compute. If a Nova CLI command
            or configuration option related to networking is not
            mentioned in this guide, it is likely not supported for
            use with OpenStack Networking. In particular, using CLI
            tools like 'nova-manage' and 'nova' to manage networks or
            IP addressing, including both fixed and floating IPs, is
            not supported with OpenStack Networking.</para>
        </warning>
        <note>
            <para>It is strongly recommended that you uninstall
                nova-network and reboot any physical nodes that had
                been running nova-network before using them to run
                OpenStack Networking. Inadvertently running the
                nova-network process while using OpenStack Networking
                can cause problems, as can stale iptables rules pushed
                down by previously running nova-network. </para>
        </note>
        <para>
        The next section describes nova.conf settings that are required
        for OpenStack Compute to work properly with OpenStack Networking,
        rather than the legacy nova-network mechanism.
        </para>
        <section xml:id="nova_with_neutron_api">
            <title>Networking API &amp; and Credential Configuration</title>
            <para>Each time a VM is provisioned or deprovisioned in
                OpenStack Compute, nova-* services communicate with
                OpenStack Networking via the standard API. To do so,
                it requires the following items in the nova.conf used
                by each <systemitem class="service">nova-compute</systemitem> and nova-api instance:  </para>
            <itemizedlist>
                <listitem>
                    <para>network_api_class: must be modified from default to
                        'nova.network.neutronv2.api.API' to indicate that OpenStack Networking
                        should be used rather than the traditional nova-network networking
                        model.</para>
                </listitem>
                <listitem>
                    <para>neutron_url: must include the hostname/IP and port of the neutron-server
                        instance for this deployment.</para>
                </listitem>
                <listitem>
                    <para>neutron_auth_strategy: should be kept as default 'keystone' for all
                        production deployments.</para>
                </listitem>
                <listitem>
                    <para>neutron_admin_tenant_name: must be modified to be the name of the service
                        tenant created in the above section on OpenStack Identity
                        configuration.</para>
                </listitem>
                <listitem>
                    <para>neutron_admin_username: must be modified to be the name of the user
                        created in the above section on OpenStack Identity configuration.</para>
                </listitem>
                <listitem>
                    <para>neutron_admin_password: must be modified to be the password of the user
                        created in the above section on OpenStack Identity configuration.</para>
                </listitem>
                <listitem>
                    <para>neutron_admin_auth_url: must be modified to point to the OpenStack
                        Identity server IP and port. This is the Identity (keystone) admin API
                        server IP and port value, and not the Identity service API IP and
                        port.</para>
                </listitem>
            </itemizedlist>
        </section>
        <section xml:id="nova_config_security_groups">
        <title>Security Group Configuration</title>
        <para>The OpenStack Networking Service provides security group functionality using a
                mechanism that is more flexible and powerful than the security group capabilities
                built into OpenStack Compute. Thus, when using OpenStack Networking, nova.conf
                should always disable built-in security groups and proxy all security group calls to
                the OpenStack Networking API. Failure to do so will result in conflicting security
                policies being simultaneously applied by both services. To proxy security groups to
                Neutron, use the following configuration values:</para>
            <itemizedlist>
                <listitem>
                    <para>
                        firewall_driver : must be set to
                        'nova.virt.firewall.NoopFirewallDriver'
                        so that <systemitem class="service">nova-compute</systemitem> does not perform iptables-based
                        filtering itself.
                    </para>
                </listitem>
                <listitem>
                    <para> security_group_api : must be set to 'neutron' so that all security group
                        requests are proxied to the OpenStack Network Service. </para>
                </listitem>
            </itemizedlist>
        </section>
        <section xml:id="nova_config_metadata">
        <title>Metadata Configuration</title>
        <para>The OpenStack Compute service allows VMs to query metadata associated with a VM by
                making a web request to a special 169.254.169.254 address. Neutron supports proxying
                those requests to nova-api, even when the requests are made from isolated networks,
                or from multiple networks that use overlapping IP addresses. Enabling this requires
                setting the following fields in nova.conf: </para>
            <itemizedlist>
                <listitem>
                    <para> service_neutron_metadata_proxy: must be set to 'true', otherwise nova-api
                        will not properly respond to requests from the neutron-metadata-agent. </para>
                </listitem>
                <listitem>
                    <para> neutron_metadata_proxy_shared_secret: a string "password" value that
                        should also be configured in the metadata_agent.ini file in order to
                        authenticate requests made for metadata. The default value of the empty
                        string in both files will allow metadata to function, but will be insecure
                        if any non-trusted entities have access to the metadata APIs exposed by
                        nova-api. </para>
                </listitem>
            </itemizedlist>
            <note><para>As a precaution, even when using neutron_metadata_proxy_shared_secret, it is recommended that
                    you do not expose metadata using the same nova-api instances that are used for
                    tenants. Instead, run a dedicated set of nova-api instances for metadata
                    available only on your management network. Whether a given nova-api instance
                    exposes metadata APIs is determined by the value of 'enabled_apis' in its
                    nova.conf. </para></note>
        </section>
        <section xml:id="nova_with_neutron_vifplugging">
            <title>Vif-plugging Configuration</title>
            <para>When <systemitem class="service">nova-compute</systemitem> creates a VM, it must "plug" each
                of the VM's vNICs into an OpenStack Networking
                controlled virtual switch, and inform the virtual
                switch about the OpenStack Networking port-id
                associated with each vNIC.  Different OpenStack Networking
                plugins may require different types of vif-plugging.
                The type of vif-plugging to be used is specified in
                the nova.conf for each <systemitem class="service">nova-compute</systemitem> instance.
             </para>
             <para>
                The following plugins support the "port bindings" API
                extension that allows Nova to query for the type
                of vif-plugging required.
                <itemizedlist>
                <listitem><para>OVS plugin</para></listitem>
                <listitem><para>Linux Bridge Plugin</para></listitem>
                <listitem><para>NEC Plugin</para></listitem>
                <listitem><para>Big Switch Plugin</para></listitem>
                <listitem><para>Hyper-V Plugin</para></listitem>
                <listitem><para>Brocade Plugin</para></listitem>
                </itemizedlist>
            </para>
            <para>For these plugins, the default values in nova.conf
                are sufficient.  For other plugins, see the sub-sections
                below for vif-plugging configuration, or consult external
                plugin documentation.
            </para>
            <note><para>It is possible that the vif-plugging configuration
                required for <systemitem class="service">nova-compute</systemitem> will vary even within a single
                deployment if your deployment includes heterogeneous compute
                platforms (e.g., some computes hosts are KVM while others are
                ESX).
            </para></note>
            <section xml:id="nova_with_neutron_vifplugging_nvp">
                <title>Vif-plugging with Nicira NVP Plugin</title>
                <para>The choice of vif-plugging for the NVP Plugin depends
                  on what version of libvirt is in use.</para>
                <note><title>Checking your libvirt version</title>
                      <para>To check your libvirt version, use
                            <command>libvirtd
                        --version</command>.</para>
                </note>
                <itemizedlist>
                    <listitem>
                        <para>When using libvirt (version &gt;= 0.9.11):
                            libvirt_vif_driver=nova.virt.libvirt.vif.LibvirtOpenVswitchVirtualPortDriver</para>
                    </listitem>
                    <listitem>
                        <para>When using libvirt (version &lt; 0.9.11):
                            libvirt_vif_driver=nova.virt.libvirt.vif.LibvirtOpenVswitchDriver</para>
                    </listitem>
                    <listitem>
                        <para>When using ESX: no vif-plugging configuration
                            required.</para>
                    </listitem>
                    <listitem>
                        <para>When using XenServer:
                            xenapi_vif_driver=nova.virt.xenapi.vif.XenAPIOpenVswitchDriver </para>
                    </listitem>
                </itemizedlist>
                <note><para>When using libvirt &lt; 0.9.11, one must also
                 edit <filename>/etc/libvirt/qemu.conf</filename>,
                 uncomment the entry for
                 'cgroup_device_acl', add the value '/dev/net/tun' to the list
                 of items for the configuration entry, and then restart
                 libvirtd.</para></note>
            </section>
        </section>
        <section xml:id="nova_with_neutron_example">
            <title> Example nova.conf (for <systemitem class="service">nova-compute</systemitem> and nova-api)</title>
            <para>Example values for the above settings, assuming a
                cloud controller node running OpenStack Compute and
                OpenStack Networking with an IP address of 192.168.1.2
                and vif-plugging using the LibvirtHybridOVSBridgeDriver. </para>
            <screen><computeroutput>network_api_class=nova.network.neutronv2.api.API
neutron_url=http://192.168.1.2:9696
neutron_auth_strategy=keystone
neutron_admin_tenant_name=service
neutron_admin_username=neutron
neutron_admin_password=password
neutron_admin_auth_url=http://192.168.1.2:35357/v2.0

security_group_api=neutron
firewall_driver=nova.virt.firewall.NoopFirewallDriver

service_neutron_metadata_proxy=true
neutron_metadata_proxy_shared_secret=foo

# needed only for nova-compute and only for some plugins
libvirt_vif_driver=nova.virt.libvirt.vif.LibvirtHybridOVSBridgeDriver
</computeroutput> </screen>
        </section>
    </section>
</chapter>
